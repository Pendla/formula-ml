\chapter{Theoretical Framework}
% Explain concepts that we rely upon throughout the report. 

%This chapter will introduce the theoretical framework of the project.

The following sections will include an explanation of the underlying theory and physics of racing, an introduction to the challenges of digital simulation and an overview of and motivation for machine learning concepts used in the project. 

\section{Racing Theory}
\label{racing_theory}
% Started to re-write, maybe usable
% Understanding racing theory is crucial to understand what the goal of the AI driver behaviour is, and to discuss what the requirements for it are. Racing theory involves both good practises and the reasons behind them. 
% As mentioned, the type of competition is a single car performing a time attack. The goal is to drive around a track with as little time as possible. It is a little harder to 

As mentioned in \ref{purpose}, the goal of the project is to create a racing AI able to drive a car around a racing track as quickly as possible. Racing tracks are normally broad enough to allow many different paths for the driver. Different paths may differ in length but also affect the possible speed. Time is the result from both distance and speed according to the following formula:
\begin{equation}
t = \frac{d}{v}
\end{equation}
Where $d$ is the distance driven and $v$ is the average speed. The process of minimising the time is a process of both minimising the distance driven and maximising the speed. This requires skill as the two aspects needs to be balanced.

The next subsection will briefly describe the physics of racing. It is a core part of understanding how professional drivers drive, as will be described in the second next subsection.

\subsection{Underlying Physics of Racing}
%%Baka in k√§llor, bl.a. Edmond
A moving car has momentum. In order to change the momentum, for example to accelerate, decelerate, or change the direction of movement, a force must be applied. These forces are applied through the tyres. This is a restricting factor for cars since the available traction, which is the amount of force that can be applied through the tyres, is limited. If the applied force exceeds the available traction, the tyres will slide or spin. 

The brakes are generally very efficient and are mostly limited by the traction of the tyres, whereas accelerating is limited by the torque of the engine. Additionally, a car travelling forward is slowed by the air drag. When the car brakes, the tyres and the drag will work together, but an accelerating car has to work against the drag. These aspects make cars accelerate slower than they can decelerate.

As described by Newtonian mechanics, the kinetic energy of a moving object increases quadratically with the speed. A consequence is that a greater force is required to change the momentum. Accelerating and braking takes longer time and the turning radius is larger. The turning radius for a circular motion is:

\begin{equation}
a_c = \frac{v^2}{r} \cite{beckman} 
\rightarrow
\frac{F_c}{m} = \frac{v^2}{r} 
\rightarrow
r = \frac{mv^2}{F_c}
\end{equation}

\noindent
Where $a_c$ is the central acceleration, $v$ is the speed, $r$ is the radius of the circular motion, $F_c$ is the central force and $m$ is the mass of the car.

The car cannot turn as much when it accelerates or brakes. When a car accelerates or brake, the amount of pressure on the tyres will change, changing the traction capabilities. This limits the amount a car accelerates or brake and turn at the same time \cite{beckman}. The effect is further increased since both turning and changing the speed requires traction and share the same traction budget. Thus turning the car uses some of the available traction which reduces the amount the car can accelerate \cite{beckman}. 

% Turning changing velocity requires traction, thus 
%The effect is further increased as the tyres cannot produce traction for multiple directions as well as for a single direction\cite{beckman}. 

Due to the shape of a racing car, air drag contribute to the traction by pushing the car down. This effect, which is called down force, grows as the speed increases.

\subsection{Introduction to Racing Lines}
A racing line denotes the path a car drive around the track. It is an expression that include both the positioning and speed of the car.

% OLD version
%As previously mentioned, driving fast and driving short are the key aspects to optimise, but they sometimes opposite each other. If the car drives fast, the turning radius is increased and the car might need to drive a longer path, which may take longer time in total. 

%However, if the car exits a curve with a higher speed, it can benefit from a reduced time spent in the next section. It is therefore generally beneficial to prioritise higher speed on longer sections\cite{beckman}, as the difference in speed will accumulate more time.

%A typical behaviour is therefore to position the car on the opposite side of where a curve is turning. This enables a larger turning radius. The car brakes as late as possible to not loose time on the previous section, but turns most intensively rather early in the curve, so that it can start accelerating for the next section as early as possible. This curve will result in a late apex.

As mentioned in \ref{racing_theory}, driving fast and driving short are the key aspects to optimise in order to minimise the lap times, but they sometimes counteract each other. If the car drives fast, the turning radius is increased and the car might need to drive a longer path, which may take longer time in total. 

It is generally good to keep as high speed as possible and to drive close to the inner corners. The position where the race line is closest to the inner corner is called the apex. Depending on the situation the driver may take an early, middle, or late apex, as shown in \ref{figure:apex_variants}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{race_lines}
    \caption{Representation of race lines through a 90 degree corner. Line 1 represents a late apex race line, line 2 a mid-apex and line 3 an early apex race line.}
    \label{figure:apex_variants}
\end{figure}

\noindent
If the car exits a curve with a higher speed, it can benefit from a reduced time spent in the next section. It is therefore generally beneficial to prioritise higher speed on longer sections\cite{beckman}, as the difference in speed will accumulate to a larger time difference. The optimal behaviour is therefore to break early so that a large portion of the turning can be done early in the corner, and then start to accelerate early, resulting in a late apex. This type of corner is often referred to as a type 1 corner \cite{edmondson}.

However, when a corner ends a straight section and is not followed by a different straight it is usually beneficial to brake and steer as late as possibly, to benefit mostly of the high speed before the curve \cite{edmondson}. This will cause an early apex and it is often referred to as a type 2 corner.


\section{Digital Simulation}
% - Discrete steps
% - Numerical errors

% Should we keep this section or integrate it into the implementation of the simulator section?? 

Computers have been utilised throughout the project to simulate the physics of a racing car. However, digital simulation introduces errors that potentially could affect the result. This section will present some of the key aspects of digital simulation. 

A digital computer cannot due to its discrete nature store or calculate real numbers exactly. Instead something called floating point numbers are used. Floating point numbers is a way to represent real numbers as discrete values. It works by storing the significant digits of a number together with a value representing an exponent. The floating point number can be calculated by multiplying the significant digits with a fixed base raised to the stored exponent.

The simulator holds a state of what it simulates. The simulation progress by calculating what the new state should be after an amount of time have elapsed. One of the limitations of this way of simulating is that it difficult to take in to account events that should have occurred during the time slice, or multiple degrees of derivatives. 

Due to computers being unable to handle continuous calculations they must rely on models of reality. This will introduce numerical errors in the calculations. It is therefore important to motivate that the errors introduced are small enough for it to not decrease the quality of the simulation.



\section{Machine Learning}
Machine learning is the field of study that concentrates on algorithms that can be said to learn \cite{glossary}. This section will cover the machine learning theory and concepts that were considered and used within the project. Furthermore, the suitability of the different algorithms within the problem domain will be discussed.  

\subsection{Artificial Neural Networks as Knowledge Model}
Machine learning algorithms require some representation of knowledge. One such knowledge model that is in wide use is the Artificial neural network (ANN). An ANN is a mathematical model that mimics the structure of the human brain. 

The human brain is a large network of nerve cells called neurons. The neuron is a cell capable of firing an electrical pulse that can be transmitted electrically or chemically to other neurons via connections called synapses. A neuron fires its pulse when the accumulated incoming signals from other neurons reach a certain threshold. Akin to a biological neural network, an ANN is a network of artificial neurons or nodes. Each node has an output value which is calculated from a set of incoming connections. The connections are a set of weighted edges. The edges are directed, which means that they represent a signal flow from one neuron to another in the direction of the edge.

An ANN can represent a mathematical function by connecting a set of input nodes to a set of output nodes, thus representing a mapping from the input space to the output space. Between the input and output nodes, additional nodes called hidden nodes may exist. Output nodes and hidden nodes may not only be connected to the input nodes, but also other hidden nodes. These con

The function is calculated by setting the values of the input nodes and then propagating the values through the network. The propagation of values works by feeding the value of one node to the others via a nodes outbound edges. The value of a node $v$ is calculated by passing the weighted sum of the values on the incoming connections to an activation function $\phi(x)$.

\begin{equation}
    v = \phi (\sum_i{w_i v_i})
\end{equation}

\noindent
Where $w_i$ is the weight and $v_i$ is the value of an incoming connection. The choice of activation function is arbitrary but will greatly affect the nature of the represented function. Usually a sigmoid-function is used, which is a smooth step function on the form:

\begin{equation}
    S(t) = L + \frac{a}{1 + e^{-bt}}
\end{equation}

\noindent
Here $L$ denotes the lower bound of the function, $a$ defines the range of values and $b$ defines the steepness of the function. The value-range of the function is $[L, L+a]$. 

An ANN with at least two layers of hidden neurons and a sigmoid function as its activation function can be used to approximate any real function, furthermore the accuracy increases with the number of neurons \cite{mitchel:approximation}. The function approximated by an ANN can be changed by changing the topology or weights of the network. Artificial neural networks are thus useful for fitting curves to data. 



\subsection{Supervised Learning}
Supervised learning is the process of learning with a teacher or learning from examples \cite{haykin:supervised}. A large set of example data consisting of pairs of input configurations and the corresponding correct output is used. The learning process works by letting the knowledge model, for example a neural network, predict the correct output for given inputs in the data set. The knowledge model is then corrected in order to better predict the correct output. Algorithms that learn by induction often fall into the supervised learning category \cite{glossary}. 

Supervised learning algorithms are useful when the goal is to create an accurate prediction model from a large set of example data. As mentioned in chapter \ref{introduction}, it is used as a key compartment for autonomous vehicles\cite{}. This prove to some extent the quality and possibilities of the approach.

However, the primary goal of this project is to create an AI not by defining how it should behave but by defining what it should strive for. Supervised learning could certainly be used to create a racing AI that for example emulates a professional driver. It could also be used to solve one part of the problem, for example learning where to position the car on the track. However, the scarcity of available data limits the use of these algorithms.  



\subsection{Unsupervised Learning}
Unsupervised learning is a type of machine learning that in contrast to supervised learning does not learn to predict or approximate a correct output given an input, but rather learn to group sets of inputs into categories based on the input values. These algorithms are prevalent in data mining and other areas where clustering is useful. 



\subsection{Reinforcement Learning}
A central aspect of the learning process is evaluating the performance of the actor. Supervised learning algorithms compare the actors output with a set of correct values. However, if there is no data set available to train with the feedback must be acquired in some other way. Reinforcement learning algorithms solve this by scoring actors on how well they perform \cite{whiteson}. The set of example data used in supervised learning is replaced by some quantifiable measurement of performance, often calculated from a heuristic. Scoring the actor could either be done by rewarding it for beneficial actions or decisions, but also by evaluating the performance in general. 

The performance is used as the basis of some transforming process that improves the actor itself. The modification process differs between knowledge models and learning algorithms. In a neural network the process would change the weights or topology of the network in order to improve its performance.

In this project reinforcement learning is a reasonable paradigm since the performance can be evaluated by simulating how the actor drives the car. In the problem domain the effectiveness of individual actions is hard to evaluate since behaviours may be locally suboptimal but globally optimal. 

ELABORATE LAST PARAGRAPH: A problem with evaluating individual actions is that it is difficult to know what the optimal action would be. It is also difficult to know which actions in a sequence that contributed in what way to the result, and in what way they would be improved. This make algorithms like gradiant descent and backpropagation less suitable.

However, the global behaviour of an actor is easier to evaluate, for example by rewarding shorter lap times. Thus a reinforcement learning algorithm where the actors can be evaluated on this level of abstraction would be favourable. 

ADD(?): A common approach to solve reinforcement learning problems is to model the problem as a Markov Chain, often referred to Markov Decision Problem (MDP). MDP depend on that the problem has discrete states and a discrete set of actions. Therefore some algorithms need to discretesise the continuous space, which may decrease the quality of the model. The state space grow very large. 
It exist algorithms that try to approach the problem. Practical Reinforcement Learning in Continuous Spaces. CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING. 


\subsection{Neuroevolution}
\label{section:neuroevolution}
One type of reinforcement learning that is compatible with the desired mode of evaluation is neuroevolution\cite{gomez:CoSyNE}. Neuroevolution is a set of reinforcement learning algorithms that learn by emulating evolutionary processes, for example natural selection. Neuroevolution algorithms learn by evolving neural networks to solve a specific task. The evolution process works by allowing advantageous traits to remain while disadvantageous traits are removed.  

Determining whether or not a trait is advantageous is done by evaluating the performance of the AI. Performance is measured in terms of a fitness value. This value is calculated by a fitness function. The fitness function is specific to the task at hand and should be defined by what defines good behaviour for that task. Furthermore, it should be defined such that increasing its value is equivalent to increasing the performance of the AI.

The evolution process can be done on different levels of abstraction. For example, on the individual level, where well-adapted individuals are allowed to carry on their traits. It can also be done on the level of singular traits, for example connections in a neural network. In that case the traits that have a positive contribution to the performance of the AI are kept while negative traits are removed. This type of machine learning has been shown to be effective in comparison to other machine learning algorithms at solving non-linear control tasks such as the pole balancing problem \cite{gomez:efficient_nonlinear_control}.



\subsection{NEAT (Neuroevolution of Augmenting Topologies)} 
\label{theory:neat}
One neuroevolution algorithm is Neuroevolution of Augmenting Topologies, henceforth referred to as NEAT\cite{ozveren}. In NEAT the evolution process is simulated on a pool of genomes. A genome is the genetic encoding or DNA of an ANN consisting of a number of genes. Each gene represents a connection in a neural network. The genomes are grouped into species based on genetic similarity. A genome only competes with the other members of its species. The introduction of species protects the diversity of the population, which has been showed to improve the learning rate of the algorithm \cite{stanley:neat}.  

The evolution process works by culling each species based on the evaluated fitness of each genome. The fitness of each genome is evaluated by a detached and separately implemented algorithm. The worse performing half of each species is removed, the better half is allowed to pass on their genes and the best genome is kept as it is. Some species are removed due to stagnation or due to performing significantly worse than the average. The other species are allowed to breed a number of children. The number of children a species is allowed to breed is calculated from the relative average fitness of the species. 

The breeding process used in NEAT creates children by combining genes from two parent genomes and then mutating the child. The mutation is a stochastic process which may change a genome in several ways. The possible mutations are the addition of a new gene, adding a new node by splitting a gene into two, modifying the weight of a connection, disabling an enabled gene, or enabling a disabled one. The iterative process of evaluating, culling, breeding, and mutating, generates a pool a genomes. Each new pool generated is refered to as a generation in NEAT.

Another feature of NEAT is that the neural networks are constructed from a minimal initial structure. By gradually augmenting the topology of the network the resulting size of the network can remain small. Additionally, only the beneficial modifications will survive the evolutionary process. Thus useless features will be discarded, further reducing the size of the networks. A minimal structure reduces the search space of the algorithm, since there are less connection and weights to optimise. 
