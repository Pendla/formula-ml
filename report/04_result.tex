% Introduce the different experiments
% If experiment refer to each other, possibly also mention that here.

\chapter{Results \& Discussion}
This chapter presents and discusses the results that have been achieved during the project. The chapter has been divided into parts by the experiments performed, in order to present the way in which the project has developed over time and the way in which the AIs behaviour has progressed alongside these experiments.

Dividing the project into experiments has allowed for an easy way to gradually increase the complexity or change parameters in the environment of the problem in a way that is convenient to analyse and draw conclusions on the behaviour of the AI for every different experiment.

The projects that have been performed have all had great impacts on the final results. Even though not all of them present great results in themselves, they have had significant impacts in our understanding of the problem and the validation of our problem solving and modelling.

% Refer to the description in method
% What was the intended result? What did we want to analyse?
% Present the results of the experiment
    % - What did it do?
    % - Fitness
    % - Generations required before results
    % - (Population)
% Analyse the results and the meanings behind them.
    % - Was it a good result? Why/Why not?
    % - What conclusions can be drawn from the results?
    % - How could we modify this experiment in order to get additional meaningful results?

\section{Exclusive OR - Remove}
Before any conclusions could be drawn about the other experiments, the validity of the NEAT implementation had to be confirmed. This was done by performing an XOR experiment. The intended result is for the training algorithm to evolve a network with enough hidden neurons to simulate the XOR function, a non-linear function that cannot be performed by a neural network without hidden neurons.

The experiment performed well and successfully approximated the XOR function after XX generations. One can see the fitness in relation to the generation number in Figure X.X.
% TODO: Talk more about the Figure X.X and what tendencies we can see from the results.

% TODO: Write even more here we can have actual results and numbers to talk about
The result from this experiment is definitely a success, and this means that future experiments can be based upon our NEAT implementation, hopefully without encountering to many problems caused by the NEAT implementation. 




\section{Fixed speed}
% refer to the description in Method
% example: did it help to help in any way
% example: present data
% example: did the hypothesis work

After it completes a track, rewarding it for improved time or improved distance driven is analogous, since it drive at a constant speed.


\subsection{Only local perception}
[Uncertain statement: Oscillation trick do often not work for subsequent tough curves.]

The car stick to the middle of the track. If it drives in to a curve and appear away from the middle, it tries to recover. If it approached a tight curve, it would not perceive the curve until it suddenly appear to drive away from the middle. This lead to late reactions, making it impossible to get past curves if they were to tight or the speed was too high.

It usually resulted in oscillations around the mid line, usually after some disturbance like the initial curved. Some times the oscillation made it get in better position for a difficult curve, allowing it to complete the curve better. 

Oscillation will cause the car to drive longer than if it would drive straight. After completing the track, if the oscillation was not needed for taking a specific curve, it always stopped. The network managed to learn to make it stable. 

The only way it can know there is a curve, is if it find itself away from the middle. It is therefore impossible for it to sophistically prepare for an approaching curve. The only way it improved after a certain degree was if it found an accidental oscillation, an unstable solution which did not work for several subsequent difficult curves.

Training times... [insert data]

Network structure...  [insert data]

[Does is behave differently with edge distance data instead or in addition to distance to middle data? Will it stick to another lateral position than the middle?]


\subsection{Local perception and track curvature}

[All statements uncertain]

The AI had a greater ability to take tough curves as it often learned to turn before the beginning of tough turns, so it managed a slightly higher speed.

for tough turns it found solutions that positioned the car well before tough curves. It sometimes drove a straight line from the previous curve to a good position at the tough curve. There it could start to turn relatively well. However, we did not observe that it intentionally position itself as it arrived to a tough curve.

Behaviour observed...

Training times...

Network structure... 


\subsection{Shortest path}

[Some statements uncertain]

If the car drives slow enough for the turning rate to be as low as the tightest curvature of the track, the optimal path will also be the shortest possible path around the track.

The result show that the car manages to shorten the path to a great extent. The difference to drive in the middle of the track is significant.

The optimal behaviour is intuitively to always drive on the inner curves and to drive a straight line between the curves where it has to turn. Small variations on the curvature should not matter, if the edge does not intersect with the path the car drives.

The car follow the key behaviour aspects, but not to the extent that the path is optimal. We can see that it drives tightly to the inner side for very tight curves, but not for low intensity curves.

Training times...

Network structure...


\section{(Existing steering controller)}
% refer to the description in Method
% example: did it help to help in any way
% example: present data
% example: did the hypothesis work

\section{Steer and speed control}
% refer to the description in Method
% example: did it help to help in any way
% example: present data
% example: did the hypothesis work

\section{Multiple short track segments}

\section{Concluding discussion}
% Comparison of the results and discussion of the different experiments not mentioned before.
% General question formulations:
% How to help a machine learning algorithm? Opposition between general algorithms and specialised?
%
Ideas and a possible categorisation (Gabriel):

The neat mechanism
- Neat train to fulfil a declared goal, not a a description on how to do it
- What are the properties for getting stuck or to develop innovation? How well do the greedy approach work?
- How will the stochastic parameters in neat influence this behaviour?
- Do it exist certain statistical improbabilities or unavoidableness?
- Analysis: How entangled is a neural network? Can one part evolve safely without disrupting other parts? Is it possible to evolve safely? Catastrophic forgetting?
- Ability to manage multiple goals? Can it achieve one or several tasks at the same time?


Generality of results
- If it is trained for certain tracks, can it manage others?
- How stable and general is it? Can it manage the same curve in different situations? Stability for unpredicted factors?
- Over training. What do it mean, is it a risk and can it be avoided?


Neat usability
- How well do it perform with not knowing how things work?
- For how large and complex problems can it perform?
- In our experiments it controlled the car at a low level, can improvements be made if it is modelled differently by the programmer? Added abstractions? More supplemented by other parts of a solution? Several single purpose networks in modules?
- How much domain knowledge is required to make it ok/very good?
  - Degree of knowledge?
  - Type of knowledge? Examples: Structural knowledge provided by the programmer, example data, experience
  - Worth noting: excluding something unimportant also prove a kind of knowledge


Comparison to other algorithms and concepts
- How do it stand to other algorithms?
- Compare degree and type of domain knowledge needed? Example of types: Structural knowledge provided by the programmer, example data, experience


Conclusion
- Summarised evaluation of neat and other concepts dealt with in the report
- What do it mean for ML in general?



\iffalse

% Discussion of the behaviour
% Present current results
This chapter presents and discusses the results that have been achieved during the course of the project. We successfully present the car driving around the track. However the lap that is taken by the car is neither optimal in respect to the race lines nor the time that it takes for the car to travel around the track.

The experiments performed during the course of the project have given varying results. Every experiment have had a large impact on how the project has progressed and on the final results. The results for each experiment and the conclusions that could be drawn are presented and discussed in this chapter.

\section{Experiments}
% Introduce this section somehow.

\subsection{Curve Data as input}
% Present and discuss what results this method achieved for us.
% What kind of machine learning techniques did we use? What did they do differently?
% What behaviour did we see? Why is that?
% Is this behaviour similar or identical to a real race-car driver?
% Is it the most optimal route around the track, with regards to lap time?
% Can we expand this solution further? If so, how?
This experiment was the first one that was carried out with any real progress towards the goal. We managed to produce a machine learning algorithm efficient enough to drive the car around the track without crashing, however given some simplifications; The car automatically accelerates in a straight line, up to a certain point where it stops accelerating and keeps the same constant speed. The neural network has the possibility of controlling the amount of breaking and turning the car does, overriding any automatic acceleration that the car does by itself.

This results in a neural network successfully driving the car around the track. However the path taken is not the optimal one. The path starts of by oscillating left and right between the middle of the track. After a few generations of training, the neural network starts to adjust the oscillating such that the sharper curves can be taken with a wider radius. Given even more training the oscillating almost disappears completely, it only remains before and after some curves.

This behaviour is as mentioned of course not optimal, and neither is it one that a human race-car driver would chose to take. It is both longer and more complicated than would be required for simply driving around the track, without optimising for maximal speed or time.

The training algorithm seems to converge towards a simple neural network between all of the training sessions that has been performed. The neural network produced is one with only one connection between an input and an output. The training required in order to make a complete lap, takes no more than a few minutes. These factors leads us to believe that we can increase the complexity quite significantly before the search space has become to large to be solved within a reasonable time. Thus the limit of NEAT with respect to our problem has not been reached yet.


\subsection{Grid Data as input}
% Present and discuss what results this method achieved.
% What are the benefits and downsides to this compared to other approaches?

\fi