\chapter{General Discussion}


\section{The neat mechanism}
%  The topics noted with X are things I think can be included in the next version of the text

%   - Neat train to fulfil a declared goal, it is not a description on how to do it
%     - The fitness value say how good a genome is
%     - It do not base its decisions upon previous path of progress
% x - Analysis: How entangled is a neural network? Can one part evolve safely without disrupting other parts? Is it possible to evolve safely? Catastrophic forgetting?
% X - Ability to manage multiple goals? Can it achieve one or several tasks at the same time?
%   - How well do the greedy approach work?
%   - Would it be better to denote fitness based on behavioural heuristics rather than result based heuristics?

%   - What are the properties for getting stuck or to develop innovation? 
%   - Do it exist certain statistical improbabilities or unavoidableness?
%   - How will the stochastic parameters in neat influence the performance? 
%   - We see that many early solutions have very few nodes, solutions that have gone through long training have many. How much do the performance really differ? 
%   - Often only few of the input values are covered.
%

%   Wild ideas/suggestion:
% X - An image Daniel presented, showed during a long training, it was rare that networks made it around the track. After it succeeded to improve the results, or get around the track, the performance was always lost shortly after (?). Does this show that the neat algorithm in the setup we used it, is not efficient? Is avoiding local minima, too aggressive?
% X - In the neat paper, the authors stated that the training often got stuck for a while. Then, when some kind of archetype structure was found, the performance could then quickly increase as good networks was derived from the archetypes. It is not far fetched that the two steps in the process have different requirements. Maybe archetype topologies are smaller and faster to sieve. The elaboration of an archetype maybe requires more processing, as it might involve larger structures and thus larger need for tuning and compensation when evolving. Suggestion: Change the stagnation limit (and possibly other parameters) as the number of generations increases, or when certain properties relating to the role a species/genome hold. It might not be possible to find a sweet spot that works for all situations. 
%   - What has progressed after a leading genome has stagnated and died?
% X - What size of a network is beneficial for a network to probably to be an archetype? small? connect to all input values, or cover all categories of inputs? After a successful 
% X - How general will this approach be? If it is successful, will it only be it for problems that resemble characteristics from the racing problems? If, so what aspects? If not, what characteristics do it solve/target?

As previously described, NEAT is detached from the the actual problem it solves. It do not do any particular analysis of the problem and very little analysis of the results it collects along the way. The feedback it get from the problem is the fitness value. One might question how much information that single value can provide in the process of solving complex problems.

NEAT progressively builds up networks. Even if many different networks are evolving concurrently, each of them evolves in small steps. The number of changes for a particular network are rather limited for a single generation.

This requirement for a species to succeed is that the mutations for the individuals that are rewarded most, also are mutations that lead to the end goal. If they are not locally rewarded enough, they will be discarded and if the whole species perform too poorly it will go extinct for the benefit of other species and individuals that may or may not reach the end goal.

Information are hidden from the neat algorithm, it do not know or understand what it do good or what it fails with, so no directed modifications can be applied. It depend on that a better solution is withing reach of one of the currently genomes active in the pool.

If a network perform bad in comparison to the others in the same species, or if a species perform too bad in comparison to the other species they will be discarded\cite{stanley:neat}. Also if a species do not improve for a specified amount of generations, so called stagnation, it will also be discarded. A third aspect is that worse performing species will have a smaller amount of individual in its species. It therefore exist a rather designated range for where individuals and new innovation are permitted to survive. It is necessary to not fall in fitness, as well as improving before stagnation or breed a new species exploring a similar approach.

When the networks evolves, changing wights and introducing new topology, it is important that it remain functioning for the task it managed before. If it does not, it might fall out of the favourable range and becomes discarded. This kind of problematic has been called catastrophic forgetting\cite{gomez:CoSyNE} NOT REALLY WHAT THEY MEANT, THEY WERE TALKING ABOUT LEAVING A TASK AND TRAINING FOR ANOTHER, THEN RETURNING TO THE PREVIOUSLY LEARNED TASK

Based on the the previous discussion, it seems like it is important that performance and complexity are allowed to increase gradually, without the requirement for large jumps. If the solutions are required to take large enough jumps, they might not find a path to reach it. If NEAT is successful, it apparently existed a path with small progressions.

CHECK RESULT FOR THIS DISCUSSION One example of this may be the steer and speed control. It first train to complete the lap, but then, when a more complex analysis are required in order to make it possible to control speed efficiently, it may be somewhat locked in to the first strategy. It might not exist a gradual path that manages all the curves and it will temporary have a significantly decreased fitness. This lead to a problematic on wheither it is better to complete the whole track, with a limited quality of behaviours, or only a part of it with better general characteristics.

The difficulty of gradual progression may be particularly problematic when archiving behaviour with several in-excludable components. If several aspects are required to progress simultaneously, and any of them are missing, it might cause a failure. One example might be steer and speed control. If a network changed to drive at a higher speed, but at the same time do not position the car and time turning to ajust for the change, it will likely cause the car to crash. It might be the reason, or one of the component of why we do not observe the experiments to produce more optimal results.

%WHAT happens when the leading species die? HOW much progress are handed over to other species?

% CAN it improve on multiple goals, or only once at a time? How do it manage to learn behaviour with in-exclusable components?
% It is possible to add multiple edges in a few number of generations, but it is unlikely that they are the relevant ones and that they are well tuned. e.g. gas and brake. Kanske ofta utveckla en sak i taget.

RESULTS. We can see in e.g. shortest path that it finds beneficial behaviours, that often resemble the same characteristics. But it seldom learn all of the smaller details. We have not observed that it solves everything, and are together with the discussion above suspicious on wither it is able to succeed with it to.

Although the discussion deducted from the key mechanics of NEAT and the results from our study do not prove that NEAT cannot find a complete and all-round optimal solution for the kind of problem we investigated, it highlight a structural weakness.



\section{Problem modelling}
% Possible to add:
% - distance to middle, sometimes proved bad (?!?!?) in the steer and speed control experiment. If a value is easily applicable to the network, it is good. But when considering distance to middle in steer and speed, it might be too easy, and therefore a longer jump for it to learn to analyse it more properly. This is based on that the behaviour is that it drives in the middle, and that the specific data point is used to accomplish that behaviour. The middle behaviour is not present in the constant speed experiments when it is forced to drive fast and therefore has to do good positioning. 

% - However, if data is pre processed to extract a specific kind of property of the data other information might be lost. In order to not loose necessary information a greater number of inputs might be required, which may in itself increase the complexity. Example: Curve data points as today, but with values on how sharp the curve inside the segment is, then two floats are needed instead of one and one might think it is better to simply double the resolution of points instead.

% - In context of neat and curvature data: Fixed position is a compact representation. Information lay in the index/topology. In order to interpret distance to an observed object a structure in topology is required. If the exact distance for which some action should need to change, the topology need to change, which is a difficult task. Index based distances for actions maybe require an abstraction layer on top of the input in order to make them parametrised. Could an interpreted object input model improve the adjustment capabilities, example touple with distance to the curve and its properties? Then some more of the interpretation lie in the weights and not in the topology itself. modifying the topology is expensive and probably in most cases statistically impossible.

In order to reach the best results, it is important to use NEAT to its strengths and avoid its weaknesses. One aspect is how the problem is modelled for the neural network, what data is it provided with and how is the result interpreted.

The process of taking decisions based on data may be divided into three steps: (1) Process and interpret data and (2) making a decisions. It is conceived that it is beneficial to focus the responsibility of the networks as much as possible, and let it focus manly at the latter two. SHOW WITH GRID DATA EXPERIMENT??

A way to analyse different sets of data is by the information they contain and how relevant it is to the problem. If the data contain noise the training have a more difficult task to learn.

Concerning the track, it could get data straight from the representation model used by the simulator, vector points in triangles. However, it would have to learn how they relate to each other and what the relevance of them are is. The curvature data describe approximately the same thing, with a much lower amount of data. The exact coordinates of the triangles are not relevant, but how they relate to the car and how it affects the race line. 

To some level, the developer need to do the analysis of what is relevant and good information. If the data get to compact or hard to calculate with, it might get difficult to learn to use it, based on the discussion about multiple goals in "The neat mechanism".

To some extent it might also be important that the values are easily calculable, to make it simpler to find a usage. Several of the input data that was repeatedly used did not provide new information, but was other representations of data already provided. Distance to middle, right and left edge are in a sense analogous as the track in our experiments was uniform in width. The curvature segment data are simply the summation of some of the other data points.

We do often observe that both variants, distances and curvature and their transformations, are used at the same time. It suggest that both variants was usable in the training process, at least at some point. They could have been calculated from the other form of data, but that would have required a more complex network.



%Generality of results
%- How stable and general is it? Can it manage the same curve in different situations? Stability for unpredicted factors?
%- Over training. What do it mean, is it a risk and can it be avoided?

% Dicuss generality of the discovered behaviours
% Relate to the experiments, especially mirror track. 
\section{Generality of results}

One goal of the project was to find general behaviours, which means that the system should learn to drive on many different circuits instead of memorising a script of how to drive on a specific track. We showed in the mirrored track experiment that ..!!!!.. . Though that is not the only aspect that affect the generality of the solution. 

There is also the possibility of over-fitting the neural networks to the specifics of the training environment. This means that a behaviour is found that by chance works well on the training circuit, but not in general. For example if the system learns to distinguish specific locations on the track and take decisions based on which segment the car is located in instead of the track shape.




\section{Neat usability}
% - How well do it perform with not knowing how things work?
% - For how large and complex problems can it perform?
% - In our experiments it controlled the car at a low level, can improvements be made if it is modelled differently by the programmer? Added abstractions? More supplemented by other parts of a solution? Several single purpose networks in modules?
% - How much domain knowledge is required to make it ok/very good?
%   - Degree of knowledge?
%   - Type of knowledge? Examples: Structural knowledge provided by the programmer, example data, experience
%   - Worth noting: excluding something unimportant also prove a kind of knowledge
%   - Might be good in a situation where one know what behaviour is wanted, but not how to accomplish it.
% - Find a fitness function that gives smooth progress to the maximum, with as few local maximums as possible. 

As previously described, NEAT is not an algorithm designed to solve a particular problem. Instead it produces artificial neural networks through neuroevolution with reinforcement learning. The process is solely controlled by the fitness value.

This abstraction of the actual problem has two sides. Firstly, the simplicity make the usage easily implementable as few domain specific processes are needed. In case it manages to solve the problem sufficiently it require little domain knowledge from the developer, as the algorithm managed to solve the problem on its own. On the other hand, if the result is not sufficient, the solution is not easily modified. Improvement probably require action on a system level, either the actual training or the application of the neural network(?).

...

\section{Comparison to other algorithms and concepts}
- How do it stand to other algorithms?

- Compare degree and type of domain knowledge needed? Example of types: Structural knowledge provided by the programmer, example data, experience



% Discussion of the behaviour
% Present current results
% This chapter presents and discusses the results that have been achieved during the course of the project. We successfully present the car driving around the track. However the lap that is taken by the car is neither optimal in respect to the race lines nor the time that it takes for the car to travel around the track.

% The experiments performed during the course of the project have given varying results. Every experiment have had a large impact on how the project has progressed and on the final results. The results for each experiment and the conclusions that could be drawn are presented and discussed in this chapter.

% \section{Experiments}
% Introduce this section somehow.

% \subsection{Curve Data as input}
% Present and discuss what results this method achieved for us.
% What kind of machine learning techniques did we use? What did they do differently?
% What behaviour did we see? Why is that?
% Is this behaviour similar or identical to a real race-car driver?
% Is it the most optimal route around the track, with regards to lap time?
% Can we expand this solution further? If so, how?

% This experiment was the first one that was carried out with any real progress towards the goal. We managed to produce a machine learning algorithm efficient enough to drive the car around the track without crashing, however given some simplifications; The car automatically accelerates in a straight line, up to a certain point where it stops accelerating and keeps the same constant speed. The neural network has the possibility of controlling the amount of breaking and turning the car does, overriding any automatic acceleration that the car does by itself.

% This results in a neural network successfully driving the car around the track. However the path taken is not the optimal one. The path starts of by oscillating left and right between the middle of the track. After a few generations of training, the neural network starts to adjust the oscillating such that the sharper curves can be taken with a wider radius. Given even more training the oscillating almost disappears completely, it only remains before and after some curves.

% This behaviour is as mentioned of course not optimal, and neither is it one that a human race-car driver would chose to take. It is both longer and more complicated than would be required for simply driving around the track, without optimising for maximal speed or time.

% The training algorithm seems to converge towards a simple neural network between all of the training sessions that has been performed. The neural network produced is one with only one connection between an input and an output. The training required in order to make a complete lap, takes no more than a few minutes. These factors leads us to believe that we can increase the complexity quite significantly before the search space has become to large to be solved within a reasonable time. Thus the limit of NEAT with respect to our problem has not been reached yet.